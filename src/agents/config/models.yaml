# Configuration for all supported AI model providers

providers:
  openai:
    name: "openai"
    display_name: "OpenAI"
    default_model: "gpt-5"
    default_token_config:
      encoding: "o200k_base"
      base_tokens: 20
      max_tokens: 400000
      output_tokens: 128000

  anthropic:
    name: "anthropic"
    display_name: "Anthropic"
    default_model: "claude-sonnet-4-20250514"
    default_token_config:
      encoding: "cl100k_base"
      base_tokens: 30000
      max_tokens: 200000
      output_tokens: 64000

  gemini:
    name: "gemini"
    display_name: "Google Gemini"
    default_model: "gemini-2.5-pro"
    default_token_config:
      encoding: "cl100k_base"
      base_tokens: 20
      max_tokens: 1000000
      output_tokens: 65536

models:
  # OpenAI Models
  openai:

    qwen/qwen3-next-80b-a3b-instruct:
      name: "qwen/qwen3-next-80b-a3b-instruct"
      display_name: "Qwen 3 Next 80B A3B Instruct"
      provider: "openai"
      token_config:
        encoding: "o200k_base"
        base_tokens: 20
        max_tokens: 400000
        output_tokens: 128000
      pricing:
        input_per_1m: 3.00
        output_per_1m: 12.00
        cached_input_per_1m: 0.30
      capabilities:
        - "thinking"
        - "vision"
        - "streaming"
      aliases:
        - "qwen/qwen3-next-80b-a3b-instruct"
    o1:
      name: "o1"
      display_name: "OpenAI o1"
      provider: "openai"
      token_config:
        encoding: "o200k_base"
        base_tokens: 20
        max_tokens: 200000
        output_tokens: 100000
      pricing:
        input_per_1m: 15.00
        output_per_1m: 60.00
        cached_input_per_1m: 7.50
      capabilities:
        - "thinking"
        - "vision"
        - "audio"
      aliases:
        - "o1-2024-12-17"

    o3:
      name: "o3"
      display_name: "OpenAI o3"
      provider: "openai"
      token_config:
        encoding: "o200k_base"
        base_tokens: 20
        max_tokens: 200000
        output_tokens: 100000
      pricing:
        input_per_1m: 2.00
        output_per_1m: 8.00
        cached_input_per_1m: 0.50
      capabilities:
        - "thinking"
        - "vision"
        - "audio"
        - "streaming"
      aliases:
        - "o3-2025-04-16"

    o4-mini:
      name: "o4-mini"
      display_name: "OpenAI o4-mini"
      provider: "openai"
      token_config:
        encoding: "o200k_base"
        base_tokens: 20
        max_tokens: 128000
        output_tokens: 100000
      pricing:
        input_per_1m: 1.10
        output_per_1m: 4.40
        cached_input_per_1m: 0.28
      capabilities:
        - "thinking"
        - "vision"
        - "audio"
        - "streaming"
      aliases:
        - "o4-mini-2025-04-16"

    gpt-5:
      name: "gpt-5"
      display_name: "GPT-5"
      provider: "openai"
      token_config:
        encoding: "o200k_base"
        base_tokens: 20
        max_tokens: 400000
        output_tokens: 128000
      pricing:
        input_per_1m: 1.25
        output_per_1m: 10.00
        cached_input_per_1m: 0.125
      capabilities:
        - "thinking"
        - "vision"
        - "streaming"
      aliases:
        - "gpt-5-2025-08-07"

    gpt-5-pro:
      name: "gpt-5-pro"
      display_name: "GPT-5 Pro"
      provider: "openai"
      token_config:
        encoding: "o200k_base"
        base_tokens: 20
        max_tokens: 400000
        output_tokens: 128000
      pricing:
        input_per_1m: 15.0
        output_per_1m: 120.00
        cached_input_per_1m: 0.125
      capabilities:
        - "thinking"
        - "vision"
      aliases:
        - "gpt-5-pro-2025-10-06"

    gpt-5-mini:
      name: "gpt-5-mini"
      display_name: "GPT-5 Mini"
      provider: "openai"
      token_config:
        encoding: "o200k_base"
        base_tokens: 20
        max_tokens: 400000
        output_tokens: 128000
      pricing:
        input_per_1m: 0.25
        output_per_1m: 2.00
        cached_input_per_1m: 0.025
      capabilities:
        - "thinking"
        - "vision"
        - "streaming"
      aliases:
        - "gpt-5-mini-2025-08-07"

    gpt-5-nano:
      name: "gpt-5-nano"
      display_name: "GPT-5 Nano"
      provider: "openai"
      token_config:
        encoding: "o200k_base"
        base_tokens: 20
        max_tokens: 400000
        output_tokens: 128000
      pricing:
        input_per_1m: 0.05
        output_per_1m: 0.40
        cached_input_per_1m: 0.005
      capabilities:
        - "thinking"
        - "vision"
        - "streaming"
      aliases:
        - "gpt-5-nano-2025-08-07"

    gpt-5.1:
      name: "gpt-5.1"
      display_name: "GPT-5.1"
      provider: "openai"
      token_config:
        encoding: "o200k_base"
        base_tokens: 20
        max_tokens: 400000
        output_tokens: 128000
      pricing:
        input_per_1m: 1.25
        output_per_1m: 10.00
        cached_input_per_1m: 0.125
      capabilities:
        - "thinking"
        - "vision"
        - "streaming"
      aliases:
        - "gpt-5.1-2025-11-13"

    gpt-5.2:
      name: "gpt-5.2"
      display_name: "GPT-5.2"
      provider: "openai"
      token_config:
        encoding: "o200k_base"
        base_tokens: 20
        max_tokens: 400000
        output_tokens: 128000
      pricing:
        input_per_1m: 1.75
        output_per_1m: 14.00
        cached_input_per_1m: 0.125
      capabilities:
        - "thinking"
        - "vision"
        - "streaming"
      aliases:
        - "gpt-5.2-2025-12-11"

    gpt-4.1:
      name: "gpt-4.1"
      display_name: "GPT-4.1"
      provider: "openai"
      token_config:
        encoding: "o200k_base"
        base_tokens: 20
        max_tokens: 1000000
        output_tokens: 32768
      pricing:
        input_per_1m: 2.00
        output_per_1m: 8.00
        cached_input_per_1m: 0.50
      capabilities:
        - "vision"
        - "streaming"
      aliases:
        - "gpt-4.1-2025-04-14"

  # Gemini Models
  gemini:
    gemini-2.5-pro:
      name: "gemini-2.5-pro"
      display_name: "Gemini 2.5 Pro"
      provider: "gemini"
      token_config:
        encoding: "cl100k_base"
        base_tokens: 20
        max_tokens: 1000000
        output_tokens: 65536
      pricing:
        input_per_1m: 1.25
        output_per_1m: 10.00
        threshold: 200000
        input_per_1m_after: 2.50
        output_per_1m_after: 15.00
      capabilities:
        - "thinking"
        - "vision"
        - "streaming"

    gemini-2.5-flash:
      name: "gemini-2.5-flash"
      display_name: "Gemini 2.5 Flash"
      provider: "gemini"
      token_config:
        encoding: "cl100k_base"
        base_tokens: 20
        max_tokens: 1000000
        output_tokens: 65536
      pricing:
        input_per_1m: 0.30
        output_per_1m: 2.50
      capabilities:
        - "thinking"
        - "vision"
        - "streaming"

    gemini-2.5-flash-lite:
      name: "gemini-2.5-flash-lite"
      display_name: "Gemini 2.5 Flash Lite"
      provider: "gemini"
      token_config:
        encoding: "cl100k_base"
        base_tokens: 20
        max_tokens: 1000000
        output_tokens: 65536
      pricing:
        input_per_1m: 0.10
        output_per_1m: 0.40
      capabilities:
        - "thinking"
        - "vision"
        - "streaming"

    gemini-2.0-flash-exp:
      name: "gemini-2.0-flash-exp"
      display_name: "Gemini 2.0 Flash Experimental"
      provider: "gemini"
      token_config:
        encoding: "cl100k_base"
        base_tokens: 20
        max_tokens: 1000000
        output_tokens: 65536
      pricing:
        input_per_1m: 0.00
        output_per_1m: 0.00
      capabilities:
        - "vision"
        - "streaming"

    gemini-3-flash-preview:
      name: "gemini-3-flash-preview"
      display_name: "Gemini 3 Flash Preview"
      provider: "gemini"
      token_config:
        encoding: "cl100k_base"
        base_tokens: 20
        max_tokens: 1000000
        output_tokens: 65536
      pricing:
        input_per_1m: 0.00
        output_per_1m: 0.00
      capabilities:
        - "vision"
        - "streaming"

    gemini-3-pro-preview:
      name: "gemini-3-pro-preview"
      display_name: "Gemini 3 Pro Preview"
      provider: "gemini"
      token_config:
        encoding: "cl100k_base"
        base_tokens: 20
        max_tokens: 1000000
        output_tokens: 65536
      pricing:
        input_per_1m: 2.00
        output_per_1m: 12.00
        threshold: 200000
        input_per_1m_after: 4.00
        output_per_1m_after: 18.00
      capabilities:
        - "thinking"
        - "vision"
        - "streaming"

  # Anthropic Models
  anthropic:
    claude-sonnet-4-5:
      name: "claude-sonnet-4-5"
      display_name: "Claude Sonnet 4.5"
      provider: "anthropic"
      token_config:
        encoding: "cl100k_base"
        base_tokens: 30000
        max_tokens: 200000
        output_tokens: 64000
      pricing:
        input_per_1m: 3.00
        output_per_1m: 15.00
        cache_creation_per_1m: 3.75
        cache_read_per_1m: 0.30
      capabilities:
        - "thinking"
        - "streaming"
      aliases:
        - "claude-sonnet-4-5-20250929"

    claude-opus-4-1:
      name: "claude-opus-4-1"
      display_name: "Claude Opus 4.1"
      provider: "anthropic"
      token_config:
        encoding: "cl100k_base"
        base_tokens: 30000
        max_tokens: 200000
        output_tokens: 32000
      pricing:
        input_per_1m: 15.00
        output_per_1m: 75.00
        cache_creation_per_1m: 18.75
        cache_read_per_1m: 1.50
      capabilities:
        - "thinking"
        - "streaming"
      aliases:
        - "claude-opus-4-1-20250805"

    claude-sonnet-4-0:
      name: "claude-sonnet-4-0"
      display_name: "Claude Sonnet 4.0"
      provider: "anthropic"
      token_config:
        encoding: "cl100k_base"
        base_tokens: 30000
        max_tokens: 200000
        output_tokens: 64000
      pricing:
        input_per_1m: 3.00
        output_per_1m: 15.00
        cache_creation_per_1m: 3.75
        cache_read_per_1m: 0.30
      capabilities:
        - "thinking"
        - "streaming"
      aliases:
        - "claude-sonnet-4-20250514"

    claude-haiku-4-5:
      name: "claude-haiku-4-5"
      display_name: "Claude 4-5 Haiku"
      provider: "anthropic"
      token_config:
        encoding: "cl100k_base"
        base_tokens: 30000
        max_tokens: 200000
        output_tokens: 64000
      pricing:
        input_per_1m: 1.00
        output_per_1m: 5.00
        cache_creation_per_1m: 1.00
        cache_read_per_1m: 0.08
      capabilities:
        - "thinking"
        - "streaming"
      aliases:
        - "claude-haiku-4-5-20251001"
